= Amazon CloudWatch Client

include::./includes/attributes.adoc[]

You can use Amazon CloudWatch Logs to monitor, store, and access your log files from Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Route 53, and other sources.

You can find more information about CloudWatch at https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html[the AWS CloudWatch Logs website].

NOTE: The CloudWatch Logs extension is based on https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/welcome.html[AWS Java SDK 2.x].
It's a major rewrite of the 1.x code base that offers two programming models (Blocking & Async).

The Quarkus extension supports two programming models:

* Blocking access using URL Connection HTTP client (by default) or the Apache HTTP Client
* https://docs.aws.amazon.com/sdk-for-java/v2/developer-guide/basics-async.html[Asynchronous programming] based on JDK's `CompletableFuture` objects and the Netty HTTP client (by default) or the AWS CRT-based HTTP client

In this guide, we see how you can get your REST services to use CloudWatch Logs locally and on AWS.

== Prerequisites

To complete this guide, you need:

* JDK 17+ installed with `JAVA_HOME` configured appropriately
* an IDE
* Apache Maven {maven-version}
* An AWS Account to access the CloudWatch service
* Docker for your system to run CloudWatch locally for testing purposes

=== Provision CloudWatch locally via Dev Services

The easiest way to start working with CloudWatch Logs is to run a local instance using Dev Services.

=== Provision CloudWatch Manager locally manually

You can also set up a local version of CloudWatch Logs manually, first start a LocalStack container:

[source,bash,subs="verbatim,attributes"]
----
docker run --rm --name local-cloudwatch-logs --publish 4566:4582 -e SERVICES=logs -e START_WEB=0 -d localstack/localstack:3.0.1
----
This starts CloudWatch instance that is accessible on port `4566`.

Create an AWS profile for your local instance using AWS CLI:
[source,shell,subs="verbatim,attributes"]
----
$ aws configure --profile localstack
AWS Access Key ID [None]: test-key
AWS Secret Access Key [None]: test-secret
Default region name [None]: us-east-1
Default output format [None]:
----

== Solution
The application built here allows creating a log group and log stream and push logs events to it.

We recommend that you follow the instructions in the next sections and create the application step by step.
However, you can go right to the completed example.

Clone the Git repository: `git clone {quickstarts-clone-url}`, or download an {quickstarts-archive-url}[archive].

The solution is located in the `amazon-cloudwatch-logs-quickstart` {quickstarts-tree-url}/amazon-cloudwatch-logs-quickstart[directory].

== Creating the Maven project

First, we need a new project. Create a new project with the following command:

[source,bash,subs=attributes+]
----
mvn io.quarkus.platform:quarkus-maven-plugin:{quarkus-version}:create \
    -DprojectGroupId=org.acme \
    -DprojectArtifactId=amazon-cloudwatch-logs-quickstart \
    -DclassName="org.acme.cloudwatchlogs.QuarkusCloudWatchLogsSyncResource" \
    -Dpath="/sync" \
    -Dextensions="resteasy,resteasy-jackson,amazon-cloudwatch-logs,resteasy-mutiny"
cd amazon-cloudwatch-logs-quickstart
----

This command generates a Maven structure importing the RESTEasy/JAX-RS, Mutiny and Amazon CloudWatch Client extensions.
After this, the `amazon-cloudwatch-logs` extension has been added to your `pom.xml` as well as the Mutiny support for RESTEasy.

== Creating JSON REST service

In this example, we will create an application that allows us to create a log group and log stream and push logs events to it using CloudWatch Logs using a RESTful API.
The example application will demonstrate the two programming models supported by the extension.

Let's start with an abstract `org.acme.cloudwatchlogs.QuarkusCloudWatchLogsResource` class to provide the common functionality we will need for both the synchronous and asynchronous exposures.

[source,java]
----
package org.acme.cloudwatchlogs;
import software.amazon.awssdk.services.cloudwatchlogs.model.*;

import java.time.Instant;

public abstract class QuarkusCloudWatchLogsResource {

    protected CreateLogStreamRequest generateCreateLogStreamRequest(String groupName, String streamName) {
        return CreateLogStreamRequest.builder()
                    .logGroupName(groupName)
                    .logStreamName(streamName).build(); <1>
    }

    protected DescribeLogGroupsRequest generateDescribeLogGroupRequest(String groupName) {
        return DescribeLogGroupsRequest.builder()
                    .logGroupNamePattern(groupName).build(); <2>
    }

    protected CreateLogGroupRequest generateCreateLogGroupRequest(String groupName) {
        return CreateLogGroupRequest.builder().logGroupName(groupName).build(); <3>
    }

    protected PutLogEventsRequest generatePutLogEventRequest(String groupName, String streamName, String logMessage) {
        return PutLogEventsRequest.builder().logGroupName(groupName).logStreamName(streamName)
                .logEvents(InputLogEvent.builder().message(logMessage)
                        .timestamp(Instant.now().toEpochMilli()).build()).build(); <4>
    }

    protected GetLogEventsRequest generateGetLogEvents(String groupName, String streamName) {
        return GetLogEventsRequest.builder()
                .logGroupName(groupName).logStreamName(streamName)
                .build();  <5>
    }


}

----

<1> Generate a request to create a log stream for a specific group
<2> Generate a request to list created log groups
<3> Generate a request to create a log group
<4> Generate a request put log events at a specific log stream and group
<5> Generate a request to list all log events for a specific log stream and group

Now, we can extend the class and create the synchronous implementation in the `org.acme.cloudwatchlogs.QuarkusCloudWatchLogsSyncResource` class.

[source,java]
----
package org.acme.cloudwatchlogs;

import io.quarkus.logging.Log;
import jakarta.inject.Inject;
import jakarta.ws.rs.*;
import jakarta.ws.rs.core.MediaType;
import software.amazon.awssdk.services.cloudwatchlogs.CloudWatchLogsClient;
import software.amazon.awssdk.services.cloudwatchlogs.model.*;

import java.util.List;
import java.util.stream.Collectors;

@Path("/sync")
public class QuarkusCloudWatchLogsSyncLogsResource extends QuarkusCloudWatchLogsResource {
    @Inject <1>
    CloudWatchLogsClient client;

    @GET
    @Produces(MediaType.TEXT_PLAIN)
    public String listLogEventsOfStream(@QueryParam("groupName") String groupName,
                                        @QueryParam("streamName") String streamName) {

        Log.info("List Logs for " + groupName + " - " + streamName);


        List<String> messages = client.getLogEventsPaginator(
                        generateGetLogEvents(groupName, streamName)
                ).stream()
                .flatMap(getLogEventsResponse -> getLogEventsResponse.events().stream())
                .map(OutputLogEvent::message)
                .collect(Collectors.toList());


        return String.join("\n", messages);
    }

    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public String createLogStream(@FormParam("groupName") String groupName,
                                  @FormParam("streamName") String streamName) {
        Log.info("Create Log Stream for " + groupName + " - " + streamName);


        try {
            client.createLogGroup(generateCreateLogGroupRequest(groupName));
        } catch (ResourceAlreadyExistsException e) {
            Log.info("Log Group Already Exists " + groupName);
        }


        //There is a slight delay between the creation and it being available
        boolean logGroupCreated = false;

        while (!logGroupCreated) {

            logGroupCreated =  client.describeLogGroups(generateDescribeLogGroupRequest(groupName))
                    .logGroups()
                    .stream()
                    .anyMatch(logGroup -> logGroup.logGroupName().equals(groupName));

        }

        client.createLogStream(generateCreateLogStreamRequest(groupName, streamName));
        return "OK";
    }


    @PUT
    @Produces(MediaType.TEXT_PLAIN)
    public String putLogEventsForStream(@FormParam("groupName") String groupName,
                                        @FormParam("streamName") String streamName,
                                        @FormParam("message") String message) {
        Log.info("Put Log Event for " + groupName + " - " + streamName);
        client.putLogEvents(generatePutLogEventRequest(groupName, streamName, message));
        return "OK";
    }
}

----

<1> Inject the client provided by the amazon-cloudwatch-logs-logs extension

Using the Amazon CloudWatch Logs SDK, we can get & push log data to CloudWatch Logs Stream.

== Configuring CloudWatch Logs clients

Both CloudWatch Logs clients (sync and async) are configurable via the `application.properties` file that can be provided in the `src/main/resources` directory.
Additionally, you need to add to the classpath a proper implementation of the sync client. By default the extension uses the URL connection HTTP client, so
you need to add a URL connection client dependency to the `pom.xml` file:

[source,xml]
----
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>url-connection-client</artifactId>
</dependency>
----

If you want to use the Apache HTTP client instead, configure it as follows:
[source,properties]
----
quarkus.cloudwatchlogs.sync-client.type=apache
----

And add the following dependency to the application `pom.xml`:
[source,xml]
----
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>apache-client</artifactId>
</dependency>
----

If you want to use the AWS CRT-based HTTP client instead, configure it as follows:
[source,properties]
----
quarkus.cloudwatchlogs.sync-client.type=aws-crt
----

And add the following dependency to the application `pom.xml`:
[source,xml]
----
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>aws-crt-client</artifactId>
</dependency>
----


If you're going to use a local CloudWatch Logs instance, configure it as follows:

[source,properties]
----
quarkus.cloudwatchlogs.endpoint-override=http://localhost:4566 <1>

quarkus.cloudwatchlogs.aws.region=us-east-1 <2>
quarkus.cloudwatchlogs.aws.credentials.type=static <3>
quarkus.cloudwatchlogs.aws.credentials.static-provider.access-key-id=test-key
quarkus.cloudwatchlogs.aws.credentials.static-provider.secret-access-key=test-secret
----

<1> Override the CloudWatch client to use LocalStack instead of the actual AWS service
<2> Localstack defaults to `us-east-1`
<3> The `static` credentials provider lets you set the `access-key-id` and `secret-access-key` directly

If you want to work with an AWS account, you can simply remove or comment out all Amazon CloudWatch related properties. By default, the CloudWatch client extension will use the `default` credentials provider chain that looks for credentials in this order:

include::./amazon-credentials.adoc[]

And the region from your AWS CLI profile will be used.

== Next steps

=== Packaging

Packaging your application is as simple as `./mvnw clean package`.
It can then be run with `java  -jar target/quarkus-app/quarkus-run.jar`.

With GraalVM installed, you can also create a native executable binary: `./mvnw clean package -Dnative`.
Depending on your system, that will take some time.

=== Going asynchronous

Thanks to the AWS SDK v2.x used by the Quarkus extension, you can use the asynchronous programming model out of the box.

Create a `org.acme.cloudwatchlogs.QuarkusCloudWatchAsyncResource` REST resource that will be similar to our `QuarkusCloudWatchSyncResource` but using an asynchronous programming model.

[source,java]
----
package org.acme.cloudwatchlogs;

import io.quarkus.logging.Log;
import io.smallrye.mutiny.Multi;
import io.smallrye.mutiny.Uni;
import jakarta.inject.Inject;
import jakarta.ws.rs.*;
import jakarta.ws.rs.core.MediaType;
import software.amazon.awssdk.services.cloudwatchlogs.CloudWatchLogsAsyncClient;
import software.amazon.awssdk.services.cloudwatchlogs.model.*;
import software.amazon.awssdk.services.cloudwatchlogs.paginators.GetLogEventsPublisher;

import java.time.Duration;
import java.util.function.Supplier;

@Path("/async")
public class QuarkusCloudWatchLogsAsyncLogsResource extends QuarkusCloudWatchLogsResource {

    @Inject
    CloudWatchLogsAsyncClient client;

    @GET
    @Produces(MediaType.TEXT_PLAIN)
    public Uni<String> listLogEventsOfStream(@QueryParam("groupName") String groupName,
                                             @QueryParam("streamName") String streamName) {

        return Multi.createFrom().<OutputLogEvent>emitter((emitter) -> {
                    Log.info("List Logs for " + groupName + " - " + streamName);
                    GetLogEventsPublisher paginator = client
                            .getLogEventsPaginator(
                                    generateGetLogEvents(groupName, streamName)
                            );
                    paginator.doAfterOnComplete(emitter::complete)
                            .doAfterOnError(emitter::fail)
                            .subscribe(response -> response.events()
                                    .forEach(emitter::emit));
                }).map(OutputLogEvent::message)
                .collect().asList()
                .map(value -> String.join(", ", value));
    }

    private static class LogGroupNotFoundYet extends Throwable {
    }

    @POST
    @Produces(MediaType.TEXT_PLAIN)
    public Uni<String> createLogStream(@FormParam("groupName") String groupName,
                                       @FormParam("streamName") String streamName) {
        Log.info("Create Log Stream for " + groupName + " - " + streamName);


        final Supplier<Uni<CreateLogGroupResponse>> createLogGroupRequest = () ->
                Uni.createFrom().completionStage(
                        client.createLogGroup(generateCreateLogGroupRequest(groupName))
                );


        final Supplier<Uni<CreateLogStreamResponse>> createLogStreamRequest = () -> Uni.createFrom().completionStage(
                client.createLogStream(generateCreateLogStreamRequest(groupName, streamName))
        );

        final Uni<Void> ignore = Uni.createFrom().voidItem();


        final Supplier<Uni<DescribeLogGroupsResponse>> describeLogGroupsRequest = () -> Uni.createFrom().completionStage(
                client.describeLogGroups(generateDescribeLogGroupRequest(groupName))
        );

        final Supplier<Uni<DescribeLogGroupsResponse>> awaitForGroupToBeAvailable = () -> describeLogGroupsRequest.get()
                .flatMap(response -> {
                            boolean logGroupCreated = response.logGroups().stream()
                                    .anyMatch(logGroup -> logGroup.logGroupName().equals(groupName));

                            if (logGroupCreated) {
                                return Uni.createFrom().item(response);
                            } else {
                                return Uni.createFrom().failure(new LogGroupNotFoundYet());
                            }
                        }
                ).onFailure(LogGroupNotFoundYet.class).retry()
                .withBackOff(Duration.ofMillis(100))
                .indefinitely();


        Uni<Void> createLogGroupIfNotExists = describeLogGroupsRequest.get().flatMap(
                describeLogGroupsResponse -> {
                    if (describeLogGroupsResponse.logGroups().isEmpty()) {
                        return createLogGroupRequest.get().flatMap(createLogGroupResponse -> ignore);
                    } else {
                        return ignore;
                    }
                }
        );

        return createLogGroupIfNotExists
                        .onFailure(ResourceAlreadyExistsException.class)
                        .recoverWithUni(ignore)
                        .flatMap(ignored -> awaitForGroupToBeAvailable.get())
                        .flatMap(ignored -> createLogStreamRequest.get())
                        .map(response -> "OK");


    }

    @PUT
    @Produces(MediaType.TEXT_PLAIN)
    public Uni<String> putLogEventsForStream(@FormParam("groupName") String groupName,
                                             @FormParam("streamName") String streamName, @FormParam("message") String message) {
        Log.info("Put Log Event for " + groupName + " - " + streamName);

        return Uni.createFrom().completionStage(
                client.putLogEvents(generatePutLogEventRequest(groupName, streamName, message))
        ).map(response -> "OK");

    }


}
----

Note that the `CloudWatchAsyncClient` behaves just like the `CloudWatchClient`, but returns `CompletionStage` objects which we use to create `Uni`/`Multi` instances, and then transform the emitted item.

To enable the asynchronous client, we also need to add the Netty HTTP client dependency to the `pom.xml`:

[source,xml]
----
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>netty-nio-client</artifactId>
</dependency>
----

If you want to use the AWS CRT-based HTTP client instead, configure it as follows:
[source,properties]
----
quarkus.cloudwatchlogs.async-client.type=aws-crt
----

And add the following dependency to the application `pom.xml`:
[source,xml]
----
<dependency>
    <groupId>software.amazon.awssdk</groupId>
    <artifactId>aws-crt-client</artifactId>
</dependency>
----

== Configuration Reference

include::./includes/quarkus-amazon-cloudwatch-logs.adoc[]
